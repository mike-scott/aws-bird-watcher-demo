{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae920b4-3a29-4fc0-8b15-c1c1ddc0e318",
   "metadata": {},
   "source": [
    "# Setup dependencies\n",
    "\n",
    "**Before you begin, you will need your API Token from AI Hub.**  \n",
    "To get this value, log into AI Hub and copy it from [here](https://app.aihub.qualcomm.com/account/).  \n",
    "Then open the `aihub_api_token.txt` file and paste it there.  \n",
    "Use CTRL-S to save the file and close it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6d0b2-e491-4ee7-ae20-7f893d660b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Fix error:\n",
    "# ImportError: libGL.so.1: cannot open shared object file: No such file or directory\n",
    "!sudo apt-get install -q -y libgl1\n",
    "\n",
    "# Fix error:\n",
    "# TensorFlow SavedModel: export failure âŒ 167.2s: libusb-1.0.so.0: cannot open shared object file: No such file or directory\n",
    "!sudo apt-get install -q -y libusb-1.0-0-dev\n",
    "\n",
    "# Install and configure qai-hub for Quantize steps\n",
    "!{sys.executable} -m pip install -q onnxruntime\n",
    "\n",
    "# Clone Ultralytics YOLOv5\n",
    "![ ! -d \"yolov5\" ] && git clone https://github.com/ultralytics/yolov5 -b master\n",
    "# pin to known SHA on 2024-11-25 for reproducability\n",
    "!cd yolov5 && git reset --hard 882c35fc43a4d7175ff24e8e20b0ec0636d75f49\n",
    "\n",
    "# Install yolo and dependencies\n",
    "!{sys.executable} -m pip install -q -r yolov5/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409370d0-3d92-4438-ab46-9964557de2bd",
   "metadata": {},
   "source": [
    "# Configure settings\n",
    "\n",
    "The following block sets the configuration for building the model.\n",
    "\n",
    "NOTES:\n",
    "- To setup the **FULL** training session change `SAMPLE_ONLY = False`.  Training will take a long time once all of the classes are enabled.\n",
    "- If you run tests with `SAMPLE_ONLY = True` and then change to `SAMPLE_ONLY = False`, **you will need to re-run \"Download and prepare the dataset\"**.\n",
    "- **If you restart the kernel this block MUST always be re-run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3beb4cf-97af-491d-a343-6175e6dfb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the dataset to 5 classes in order to test training quickly, change to False for full training\n",
    "SAMPLE_ONLY = True\n",
    "if SAMPLE_ONLY:\n",
    "    CLASS_FILTER = [17, 36, 47, 68, 73]\n",
    "else:\n",
    "    CLASS_FILTER = []\n",
    "CLASS_LIMIT = 80 # gst-plugin-mlvdetection currently rejects a model with more than 80 classes\n",
    "EXPORT_CLASS_LIMIT = 4 # images per class to be used for export calibration\n",
    "\n",
    "# Dataset settings\n",
    "DATASET_NAME = \"CUB_200_2011\"\n",
    "DATASET_FILENAME = DATASET_NAME + \".tgz\"\n",
    "LABELS_FILENAME = DATASET_NAME + \".labels\"\n",
    "LABELS_COLOR = \"0x00FF00FF\"\n",
    "DATA_DIR = DATASET_NAME + \"/\"\n",
    "\n",
    "# Model and training settings\n",
    "MODEL_NAME = \"yolov5m\"\n",
    "MODEL_FILENAME = f\"{MODEL_NAME}.pt\"\n",
    "MODEL_INPUT_PIXEL_SIZE = 320\n",
    "if SAMPLE_ONLY:\n",
    "    TRAINING_EPOCHS = 250\n",
    "else:\n",
    "    TRAINING_EPOCHS = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca71cfc-ae7d-4152-bcb6-3b3b4e42b6b8",
   "metadata": {},
   "source": [
    "# Download and prepare the dataset\n",
    "\n",
    "The dataset used for this project is: Caltech-UCSD Birds-200-2011 (CUB-200-2011)  \n",
    "More information on this dataset can be found [here](https://www.vision.caltech.edu/datasets/cub_200_2011/).\n",
    "\n",
    "To prepare the dataset for training use:\n",
    "- Several text files are parsed for image data and combined into a DataFrame\n",
    "- Using the `training` field, the images are split into different folders for training and validation\n",
    "- A dataset configuration file under the `datasets/` folder is created to describe where the images are and the related class names\n",
    "- A labels file containing class data is generated for use on the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec926769-94f5-4f86-8db0-cb0cecaf0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "![ -z \"$MODEL_NAME\" ] && echo \"ERROR!! No model settings re-run \\\"Configure settings\\\" step above!\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def convert_coco_to_yolo(img_size, bbox):\n",
    "    x_center = (2*bbox[0] + bbox[2])/(2*img_size[0])\n",
    "    y_center = (2*bbox[1] + bbox[3])/(2*img_size[1])\n",
    "    width = bbox[2]/img_size[0]\n",
    "    height = bbox[3]/img_size[1]\n",
    "    return (round(x_center, 6), round(y_center, 6), round(width, 6), round(height, 6))\n",
    "\n",
    "def append_file(filename, line):\n",
    "    with open(filename, \"a\") as file:\n",
    "        file.write(line)\n",
    "        file.close()\n",
    "\n",
    "print(\"Downloading CUB_200_2011 files ...\")\n",
    "![ ! -f \"$DATASET_FILENAME\" ] && [ ! -d \"$DATA_DIR\" ] && wget --no-check-certificate -q -O $DATASET_FILENAME https://data.caltech.edu/records/65de6-vp158/files/CUB_200_2011.tgz?download=1\n",
    "\n",
    "print(\"Extracting CUB_200_2011 files ...\")\n",
    "# Unzip and cleanup the old compressed file\n",
    "![ ! -d \"$DATA_DIR\" ] && tar -xf $DATASET_FILENAME\n",
    "\n",
    "print(\"Clearing old configured dataset flles ...\")\n",
    "\n",
    "# Remove data archive\n",
    "!rm -rf $DATASET_FILENAME\n",
    "\n",
    "# read main list of images\n",
    "df = pd.read_csv(DATA_DIR + \"images.txt\", sep=' ',\n",
    "                 names=[\"id\", \"filepath\"])\n",
    "# merge list of image_id to class labels\n",
    "df = df.merge(pd.read_csv(DATA_DIR + \"image_class_labels.txt\", sep=' ',\n",
    "                          names=[\"id\", \"class_id\"]), on=\"id\")\n",
    "# merge list of image_id to training flag\n",
    "df = df.merge(pd.read_csv(DATA_DIR + \"train_test_split.txt\", sep=' ',\n",
    "                          names=[\"id\", \"training\"]), on=\"id\")\n",
    "# merge list of image_id to bounding box data\n",
    "df = df.merge(pd.read_csv(DATA_DIR + \"bounding_boxes.txt\", sep=' ',\n",
    "                          names=[\"id\", \"x_min\", \"y_min\", \"width\", \"height\"]), on=\"id\")\n",
    "\n",
    "classes_df = pd.read_csv(DATA_DIR + \"classes.txt\", sep=' ',\n",
    "                         names=[\"class_id\", \"class_name\"])\n",
    "df = df.merge(classes_df, on=\"class_id\")\n",
    "\n",
    "print(\"Generating dataset and label files ...\")\n",
    "\n",
    "# Create dataset and calibration folders\n",
    "!rm -rf datasets/\n",
    "!mkdir -p datasets/$DATASET_NAME/images/test\n",
    "!mkdir -p datasets/$DATASET_NAME/images/train\n",
    "!mkdir -p datasets/$DATASET_NAME/images/val\n",
    "!mkdir -p datasets/$DATASET_NAME/labels/train\n",
    "!mkdir -p datasets/$DATASET_NAME/labels/val\n",
    "\n",
    "# Remove old labels file\n",
    "!rm -rf $LABELS_FILENAME\n",
    "\n",
    "# copy the dataset template\n",
    "!cp CUB_200_2011.yaml.template datasets/CUB_200_2011.yaml\n",
    "\n",
    "class_ids = sorted(df['class_id'].drop_duplicates())\n",
    "class_counter = -1\n",
    "for c_id in class_ids:\n",
    "    if len(CLASS_FILTER) == 0 or c_id in CLASS_FILTER:\n",
    "        class_counter += 1\n",
    "        if class_counter >= CLASS_LIMIT:\n",
    "            break\n",
    "\n",
    "        # Parse the class name\n",
    "        c_name = classes_df[classes_df['class_id'] == c_id]['class_name'].array[0].split(\".\")[1]\n",
    "        print(f\"Parsing: {c_name}\")\n",
    "        # append to the dataset config\n",
    "        append_file(f\"datasets/{DATASET_NAME}.yaml\", f\"  {class_counter}: {c_name}\\n\")\n",
    "        # append to the labels file\n",
    "        append_file(LABELS_FILENAME, f'(structure)\"{c_name.replace(\" \", \"-\").replace(\"_\", \"-\").lower()},id=(guint)0x{class_counter:0>4X},color=(guint){LABELS_COLOR};\"\\n')\n",
    "\n",
    "        for image_id in df[df['class_id'] == c_id]['id']:\n",
    "            image_dfs = df[df['id'] == image_id]\n",
    "            filepath_orig = image_dfs['filepath'].array[0]\n",
    "            filename_new = filepath_orig.split(\"/\")[1]\n",
    "            label_filename = filename_new.split(\".\")[0] + \".txt\"\n",
    "\n",
    "            # convert from bounding box data to YOLO style x_center,y_center,w,h box\n",
    "            img_size = Image.open(f\"{DATASET_NAME}/images/{filepath_orig}\").size\n",
    "            bbox = (image_dfs['x_min'].array[0], image_dfs['y_min'].array[0], image_dfs['width'].array[0], image_dfs['height'].array[0])\n",
    "            yolo_box = convert_coco_to_yolo(img_size, bbox)\n",
    "\n",
    "            if image_dfs['training'].array[0] == 1:\n",
    "                loc = \"train\"\n",
    "            if image_dfs['training'].array[0] == 0:\n",
    "                loc = \"val\"\n",
    "\n",
    "            # TODO: copy -> rename\n",
    "            shutil.copy(f\"{DATASET_NAME}/images/{filepath_orig}\", f\"datasets/{DATASET_NAME}/images/{loc}/{filename_new}\")\n",
    "            # Create label file: <class_id> <x_center> <y_center> <width> <height>\n",
    "            with open(f\"datasets/{DATASET_NAME}/labels/{loc}/{label_filename}\", \"w\") as label_file:\n",
    "                label_file.write(f\"{class_counter} {yolo_box[0]} {yolo_box[1]} {yolo_box[2]} {yolo_box[3]}\\n\")\n",
    "\n",
    "# Create calibration data (in JPG format -- later it will be converted to RAW)\n",
    "!rm -rf calibration/\n",
    "!mkdir -p calibration/\n",
    "\n",
    "# For SAMPLE_ONLY we use the limited val folder data as calibration for quantize operations\n",
    "# For !SAMPLE_ONLY the val data is too large: create export dir with only 4 calibration images per class type (For 80 classes == ~320 images)\n",
    "src_images_dir = f\"datasets/{DATA_DIR}/images/val/\"\n",
    "dst_images_dir = f\"calibration/\"\n",
    "\n",
    "# Setup export directory for calibration data\n",
    "print(\"Generate calibration data ...\")\n",
    "last_class = \"\"\n",
    "translation_table = {ord(char): None for char in \"_0123456789\"}\n",
    "image_list = os.listdir(src_images_dir)\n",
    "export_counter = 0\n",
    "for image_path in sorted(image_list):\n",
    "    if image_path.endswith(\".jpg\"):\n",
    "        export_counter += 1\n",
    "        unique_name = image_path.translate(translation_table).lower()\n",
    "        if unique_name != last_class:\n",
    "            export_counter = 1\n",
    "            last_class = unique_name\n",
    "        if SAMPLE_ONLY or export_counter <= EXPORT_CLASS_LIMIT:\n",
    "            shutil.copy(os.path.join(src_images_dir, image_path), dst_images_dir)\n",
    "\n",
    "# Create calibration download\n",
    "!tar -czf calibration.tar.gz calibration/\n",
    "\n",
    "# Download test images\n",
    "!wget --no-check-certificate -q -O datasets/$DATASET_NAME/images/test/multi-goldfinch-1.jpg https://t3.ftcdn.net/jpg/01/44/64/36/500_F_144643697_GJRUBtGc55KYSMpyg1Kucb9yJzvMQooW.jpg\n",
    "!wget --no-check-certificate -q -O datasets/$DATASET_NAME/images/test/northern-flicker-1.jpg https://upload.wikimedia.org/wikipedia/commons/5/5c/Northern_Flicker_%28Red-shafted%29.jpg\n",
    "!wget --no-check-certificate -q -O datasets/$DATASET_NAME/images/test/northern-cardinal-1.jpg https://cdn.pixabay.com/photo/2013/03/19/04/42/bird-94957_960_720.jpg\n",
    "!wget --no-check-certificate -q -O datasets/$DATASET_NAME/images/test/blue-jay-1.jpg https://cdn12.picryl.com/photo/2016/12/31/blue-jay-bird-feather-animals-b8ee04-1024.jpg\n",
    "!wget --no-check-certificate -q -O datasets/$DATASET_NAME/images/test/hummingbird-1.jpg http://res.freestockphotos.biz/pictures/17/17875-hummingbird-close-up-pv.jpg\n",
    "\n",
    "# Remove the original data now that we've created the dataset\n",
    "!rm -rf $DATA_DIR\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22285f0-1b4f-4d7e-b924-9f31a337102a",
   "metadata": {},
   "source": [
    "# Train and validate our model\n",
    "\n",
    "If the `runs/` directory is removed (for cleaning), be sure to:\n",
    "- Restart the instance kernel\n",
    "- Re-run the \"Configure settings\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a86d11-78b5-4bc7-b323-b8dbade13f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "![ -z \"$MODEL_NAME\" ] && echo \"ERROR!! No model settings re-run \\\"Configure settings\\\" step above!\"\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "MODEL_FILENAME_RELPATH = f\"../{MODEL_FILENAME}\"\n",
    "DATA_CONFIG_RELPATH = f\"../datasets/{DATASET_NAME}.yaml\"\n",
    "\n",
    "# Train the model\n",
    "!cd yolov5/ && python train.py --weights $MODEL_FILENAME_RELPATH --data $DATA_CONFIG_RELPATH --epochs $TRAINING_EPOCHS --imgsz $MODEL_INPUT_PIXEL_SIZE\n",
    "\n",
    "# Validate the model\n",
    "!cd yolov5/ && python val.py --weights $MODEL_FILENAME_RELPATH --data $DATA_CONFIG_RELPATH --imgsz $MODEL_INPUT_PIXEL_SIZE\n",
    "\n",
    "# Backup best.pt after training\n",
    "shutil.copy(f\"yolov5/runs/train/exp/weights/best.pt\", f\"{MODEL_FILENAME}\")\n",
    "print(f\"Copied best weights as: {MODEL_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331a86b-d2fd-4ce9-a554-ef2f06b6c6e8",
   "metadata": {},
   "source": [
    "# Run inference using test images and unquantized model\n",
    "\n",
    "If the `runs/` directory is removed (for cleaning), be sure to:\n",
    "- Restart the instance kernel\n",
    "- Re-run the \"Configure settings\" section\n",
    "\n",
    "The results of the image tests are stored under the `yolov5/runs/detect/exp` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122356e5-85a2-4080-a32b-fb314ffb66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "![ -z \"$MODEL_NAME\" ] && echo \"ERROR!! No model settings re-run \\\"Configure settings\\\" step above!\"\n",
    "\n",
    "DATA_TEST_RELPATH = f\"../datasets/{DATASET_NAME}/images/test/\"\n",
    "DATA_CONFIG_RELPATH = f\"../datasets/{DATASET_NAME}.yaml\"\n",
    "MODEL_FILENAME_RELPATH = f\"../{MODEL_FILENAME}\"\n",
    "\n",
    "!cd yolov5/ && python detect.py --weights $MODEL_FILENAME_RELPATH --imgsz $MODEL_INPUT_PIXEL_SIZE --data $DATA_CONFIG_RELPATH --source $DATA_TEST_RELPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213de04-064c-4570-b901-8d21a3e345b3",
   "metadata": {},
   "source": [
    "# Export to TFLite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486f682-116d-45c2-b5e4-e5a4e25c052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "![ -z \"$MODEL_NAME\" ] && echo \"ERROR!! No model settings re-run \\\"Configure settings\\\" step above!\"\n",
    "\n",
    "DATA_CONFIG_RELPATH = f\"../datasets/{DATASET_NAME}-export.yaml\"\n",
    "MODEL_FILENAME_RELPATH = f\"../{MODEL_FILENAME}\"\n",
    "\n",
    "!cd yolov5/ && python export.py --include tflite --weights $MODEL_FILENAME_RELPATH --imgsz $MODEL_INPUT_PIXEL_SIZE --data $DATA_CONFIG_RELPATH\n",
    "\n",
    "print(\"Done!\")\n",
    "print(f\"Download model file: {MODEL_NAME}_fp16.tflite\")\n",
    "print(f\"Download labels file: {LABELS_FILENAME}\")\n",
    "print(\"Download calibration images: calibration.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e92205-350c-44fa-9d23-bf6c637fae64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
